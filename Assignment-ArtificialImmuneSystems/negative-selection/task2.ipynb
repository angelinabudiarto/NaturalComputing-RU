{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Computing, assignment 3 - task 2\n",
    "\n",
    "Group 8 - Guus, Bono, Charlotte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/charlottecvn/Downloads/Natural Computing/negative-selection\n"
     ]
    }
   ],
   "source": [
    "# current directory\n",
    "print(os.getcwd())\n",
    "\n",
    "syscalls_folder = 'syscalls'\n",
    "results_folder = 'Task2'\n",
    "subfolders = ['snd-cert', 'snd-unm']\n",
    "test_files_indexes = ['1', '2', '3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "def process_data_train(input_file, output_file, chunk_size=7):\n",
    "    with open(input_file, 'r') as df:\n",
    "        lines = df.readlines()\n",
    "        output_data = open(output_file, 'w+')\n",
    "        for idx, line in enumerate(lines):\n",
    "            for i in range(len(line)-chunk_size): \n",
    "                output_data.write(f'{line[i:i+chunk_size]}\\n')\n",
    "                \n",
    "    with open (output_file) as new_df:\n",
    "        out_new = new_df.read()\n",
    "        out_new = out_new.splitlines()\n",
    "    \n",
    "    return out_new\n",
    "\n",
    "def process_data_test(input_file, output_file, lbl_input, lbl_ouput, chunk_size=7):\n",
    "    with open(input_file, 'r') as df:\n",
    "        lines = df.readlines()\n",
    "        output_test = open(output_file, 'w+')\n",
    "        output_lbls = open(lbl_ouput, 'w+')\n",
    "        for idx, line in enumerate(lines):\n",
    "            for i in range(len(line)-chunk_size): \n",
    "                output_lbls.write(f'{lbl_input[idx]}\\n')\n",
    "                output_test.write(f'{line[i:i+chunk_size]}\\n')\n",
    "\n",
    "    with open(output_file) as df_test:\n",
    "        test_new = df_test.read()\n",
    "        test_new = test_new.splitlines()  \n",
    "        \n",
    "    with open(lbl_ouput) as df_lbls:\n",
    "        lbls_new = df_lbls.read()\n",
    "        lbls_new = lbls_new.splitlines()\n",
    "    \n",
    "    return test_new, lbls_new\n",
    "\n",
    "\n",
    "def load_data(input_file):\n",
    "    with open (input_file) as df:\n",
    "        out = df.read()\n",
    "        out = out.splitlines()\n",
    "    return out\n",
    "\n",
    "#snd_cert data\n",
    "sndcert_train = process_data_train(f\"{syscalls_folder}/{subfolders[0]}/{subfolders[0]}.train\", \n",
    "                                   f\"{results_folder}/{subfolders[0]}.train\")\n",
    "\n",
    "sndcert_lbls1 = load_data(f\"{syscalls_folder}/{subfolders[0]}/{subfolders[0]}.{test_files_indexes[0]}.labels\")\n",
    "sndcert_lbls2 = load_data(f\"{syscalls_folder}/{subfolders[0]}/{subfolders[0]}.{test_files_indexes[1]}.labels\")\n",
    "sndcert_lbls3 = load_data(f\"{syscalls_folder}/{subfolders[0]}/{subfolders[0]}.{test_files_indexes[2]}.labels\")\n",
    "\n",
    "sndcert_test1, sndcert_lbls1 = process_data_test(f\"{syscalls_folder}/{subfolders[0]}/{subfolders[0]}.{test_files_indexes[0]}.test\", \n",
    "                                                 f\"{results_folder}/{subfolders[0]}.{test_files_indexes[0]}.test\", \n",
    "                                                 sndcert_lbls1,\n",
    "                                                 f\"{results_folder}/{subfolders[0]}.{test_files_indexes[0]}.labels\")\n",
    "\n",
    "sndcert_test2, sndcert_lbls2 = process_data_test(f\"{syscalls_folder}/{subfolders[0]}/{subfolders[0]}.{test_files_indexes[1]}.test\", \n",
    "                                                 f\"{results_folder}/{subfolders[0]}.{test_files_indexes[1]}.test\", \n",
    "                                                 sndcert_lbls2,\n",
    "                                                 f\"{results_folder}/{subfolders[0]}.{test_files_indexes[1]}.labels\")\n",
    "\n",
    "sndcert_test3, sndcert_lbls3 = process_data_test(f\"{syscalls_folder}/{subfolders[0]}/{subfolders[0]}.{test_files_indexes[2]}.test\", \n",
    "                                                 f\"{results_folder}/{subfolders[0]}.{test_files_indexes[2]}.test\", \n",
    "                                                 sndcert_lbls3,\n",
    "                                                 f\"{results_folder}/{subfolders[0]}.{test_files_indexes[2]}.labels\")\n",
    "\n",
    "sndcert_alpha = load_data(f\"{syscalls_folder}/{subfolders[1]}/{subfolders[1]}.alpha\")\n",
    "\n",
    "#snd_unm data\n",
    "sndunm_train = process_data_train(f\"{syscalls_folder}/{subfolders[1]}/{subfolders[1]}.train\", \n",
    "                                  f\"{results_folder}/{subfolders[1]}.train\")\n",
    "\n",
    "sndunm_lbls1 = load_data(f\"{syscalls_folder}/{subfolders[1]}/{subfolders[1]}.{test_files_indexes[0]}.labels\")\n",
    "sndunm_lbls2 = load_data(f\"{syscalls_folder}/{subfolders[1]}/{subfolders[1]}.{test_files_indexes[1]}.labels\")\n",
    "sndunm_lbls3 = load_data(f\"{syscalls_folder}/{subfolders[1]}/{subfolders[1]}.{test_files_indexes[2]}.labels\")\n",
    "\n",
    "sndunm_test1, sndunm_lbls1 = process_data_test(f\"{syscalls_folder}/{subfolders[1]}/{subfolders[1]}.{test_files_indexes[0]}.test\", \n",
    "                                               f\"{results_folder}/{subfolders[1]}.{test_files_indexes[0]}.test\", \n",
    "                                               sndunm_lbls1,\n",
    "                                               f\"{results_folder}/{subfolders[1]}.{test_files_indexes[0]}.labels\")\n",
    "\n",
    "sndunm_test2, sndunm_lbls2 = process_data_test(f\"{syscalls_folder}/{subfolders[1]}/{subfolders[1]}.{test_files_indexes[1]}.test\", \n",
    "                                               f\"{results_folder}/{subfolders[1]}.{test_files_indexes[1]}.test\", \n",
    "                                               sndunm_lbls2,\n",
    "                                               f\"{results_folder}/{subfolders[1]}.{test_files_indexes[1]}.labels\")\n",
    "\n",
    "sndunm_test3, sndunm_lbls3 = process_data_test(f\"{syscalls_folder}/{subfolders[1]}/{subfolders[1]}.{test_files_indexes[2]}.test\", \n",
    "                                               f\"{results_folder}/{subfolders[1]}.{test_files_indexes[2]}.test\", \n",
    "                                               sndunm_lbls3,\n",
    "                                               f\"{results_folder}/{subfolders[1]}.{test_files_indexes[2]}.labels\")\n",
    "\n",
    "sndunm_alpha = load_data(f\"{syscalls_folder}/{subfolders[1]}/{subfolders[1]}.alpha\")                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# java outputs (terminal, subprocess)\n",
    "def terminal_output (test_file, train_file, alpha_file, n, r):\n",
    "    command_java = f\"java -jar negsel2.jar -alphabet file://{alpha_file} -self {train_file} -n {n} -r {r} -c -l < {test_file}\"\n",
    "    stream = subprocess.Popen(command_java, shell=True, stderr=subprocess.STDOUT, stdout=subprocess.PIPE)\n",
    "    scores_results = [float(line.rstrip().decode('utf-8')) for line in iter(stream.stdout.readline, b'')]\n",
    "    return scores_results\n",
    "\n",
    "def compute_scores_optimized(n, r, test_file, train_file, alphabet):\n",
    "    command = 'java -jar negsel2.jar -alphabet file://\\'{}\\' -self \\'{}\\' -n {} -r {} -c -l'.format(alphabet, train_file, n, r)\n",
    "    process = subprocess.Popen([command], shell=True, stdin=subprocess.PIPE, stdout=subprocess.PIPE, close_fds=True)\n",
    "    computed_scores = []\n",
    "    with open(test_file, 'r') as test:\n",
    "        lines = test.readlines()\n",
    "        for line in lines:\n",
    "            substrings = [line[i:i+n] for i in range(len(line)-n)]\n",
    "            score = 0\n",
    "            for unique_sequence in substrings:\n",
    "                process.stdin.write(f'{unique_sequence}\\n'.encode('utf-8'))\n",
    "                process.stdin.flush()\n",
    "                output = process.stdout.readline().decode(\"utf-8\").strip()\n",
    "                score += float(output)\n",
    "            computed_scores.append(score/len(substrings))\n",
    "    return computed_scores[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to calculate the sensitivity and specificity\n",
    "def sensitivity (distinct, positive_lbls):\n",
    "    sensitivity_distinct = []\n",
    "    for i, score in enumerate(distinct):\n",
    "        positive = distinct[i:]\n",
    "        true_pos = len([score for score in positive if score[1] == 1])\n",
    "        print(true_pos)\n",
    "        sensitivity_distinct.append(true_pos / positive_lbls)\n",
    "    return sensitivity_distinct\n",
    "\n",
    "def specificity (distinct, negative_lbls):\n",
    "    specificity_distinct = []\n",
    "    for i, score in enumerate(distinct):\n",
    "        negative = distinct[:i]\n",
    "        true_neg = len([score for score in negative if score[1] == 0])\n",
    "        specificity_distinct.append(1 - true_neg / negative_lbls)\n",
    "    return specificity_distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auc output (score and plots) for the desired files\n",
    "def auc_output (test_file, train_file, labels_file, alphabet, n_values, r_values, title, title_num):\n",
    "    for n in n_values: \n",
    "        for r in r_values:\n",
    "            results = terminal_output(test_file, train_file, alphabet, n=n, r=r)\n",
    "            \n",
    "            labels = [int(i) for i in labels_file]\n",
    "            distinct_anomaly = np.unique(results)\n",
    "            \n",
    "            anomaly_labels = tuple(zip(distinct_anomaly, labels))\n",
    "            sorted_distinct = sorted(anomaly_labels, key=lambda tup: tup[0])\n",
    "        \n",
    "            auc_roc_score = metrics.roc_auc_score(labels, results)\n",
    "\n",
    "            positive_lbls = len([x for x in labels if x == 1])\n",
    "            print(positive_lbls)\n",
    "            negative_lbls = len([x for x in labels if x == 0])\n",
    "\n",
    "            sensitivity_auc = sensitivity(sorted_distinct, positive_lbls) \n",
    "            specificity_auc = specificity(sorted_distinct, negative_lbls)\n",
    "\n",
    "            plt.plot(sorted(sensitivity_auc), sorted(specificity_auc), \n",
    "                     label=f\"n={n}, r={r}; AUC: {np.round(auc_roc_score,3)}\")\n",
    "        \n",
    "    plt.plot([0, 1], [0, 1], lw=1, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('sensitivity')\n",
    "    plt.ylabel('specificity') \n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.title(f\"ROC-curve, {title}.{title_num}\")\n",
    "\n",
    "    plt.savefig('{}/task2_ROC_{}_{}.png'.format(os.path.join(os.getcwd(), results_folder), title, title_num))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_values = [7]\n",
    "r_values = [3,5,7]\n",
    "\n",
    "for i in range(len(subfolders)):\n",
    "    for j in range(len(test_files_indexes)):\n",
    "        train_file = f\"{results_folder}/{subfolders[i]}.train\"\n",
    "        test_file = f\"{results_folder}/{subfolders[i]}.{test_files_indexes[j]}.test\"\n",
    "        labels = load_data(f\"{results_folder}/{subfolders[i]}.{test_files_indexes[j]}.labels\")\n",
    "        alpha_file = f\"{syscalls_folder}/{subfolders[i]}/{subfolders[i]}.alpha\"\n",
    "        auc_output(test_file, train_file, labels, alpha_file, n_values, r_values, subfolders[i], test_files_indexes[j])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
