{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Computing, assignment 3 - task 2\n",
    "\n",
    "Group 8 - Guus, Bono, Charlotte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter #Use of container datatype, https://docs.python.org/3/library/collections.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/charlottecvn/Downloads/Natural Computing/negative-selection\n"
     ]
    }
   ],
   "source": [
    "# current directory\n",
    "print(os.getcwd())\n",
    "\n",
    "syscalls_folder = 'syscalls'\n",
    "results_folder = 'Task2'\n",
    "subfolders = ['snd-cert', 'snd-unm']\n",
    "test_files_indexes = ['1', '2', '3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "def load_train(input_file, output_file, chunk_size=7):\n",
    "    result = []\n",
    "    with open(input_file) as file:\n",
    "        for line in file:\n",
    "            result.append(line.rstrip())\n",
    "\n",
    "    train_seq = set()\n",
    "    for i in result:\n",
    "        substrings = []\n",
    "        for j in range(len(i)-chunk_size+1):\n",
    "            substrings.append(i[j:j+chunk_size])\n",
    "        train_seq.update(substrings)\n",
    "    \n",
    "    with open(output_file, 'w') as file:\n",
    "        for s in train_seq:\n",
    "            file.write(s + \"\\n\")\n",
    "\n",
    "def load_labels(input_file):\n",
    "    out = []\n",
    "    with open (input_file) as df:\n",
    "        for i in df:\n",
    "            out.append(int(i.rstrip()))\n",
    "    return out\n",
    "            \n",
    "process_seq(f\"{syscalls_folder}/{subfolders[0]}/{subfolders[0]}.train\",\n",
    "            f\"{results_folder}/{subfolders[0]}.train\")\n",
    "process_seq(f\"{syscalls_folder}/{subfolders[1]}/{subfolders[1]}.train\",\n",
    "            f\"{results_folder}/{subfolders[1]}.train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to be able to analyse according to chunk_size\n",
    "def unique_substrings(test_file, chunk_size):\n",
    "    c = []\n",
    "    with open(test_file) as file:\n",
    "        for sequence in file:\n",
    "            c.append(unique_counter(sequence.rstrip(), chunk_size))\n",
    "    return c\n",
    "\n",
    "def unique_counter(s, chunk_size):\n",
    "    c = Counter()\n",
    "    for i in range(len(s)-chunk_size+1):\n",
    "        ss = s[i:i + chunk_size]\n",
    "        c[ss] += 1\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# java outputs (terminal, subprocess) for composite anomaly score (classification)\n",
    "def terminal_output_chunks(train_file, alpha_file, test_unique, n, r):\n",
    "    command_java = f\"java -jar negsel2.jar -alphabet file://{alpha_file} -self {train_file} -n {n} -r {r} -c -l\"\n",
    "    stream = subprocess.Popen([command_java], shell=True, stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n",
    "    scores_results = []\n",
    "    \n",
    "    for sub in test_unique:\n",
    "        scores = []\n",
    "        for sequence_i in sub.keys():\n",
    "            stream.stdin.write(sequence_i.encode('utf-8'))\n",
    "            stream.stdin.write(b'\\n')\n",
    "            stream.stdin.flush()\n",
    "            output = stream.stdout.readline()\n",
    "            score = float(output.rstrip()) * sub[sequence_i]\n",
    "            scores.append(score)\n",
    "        scores_results.append(sum(scores)/sum(sub.values()))\n",
    "    \n",
    "    return scores_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to calculate the sensitivity and specificity\n",
    "def sensitivity (distinct, positive_lbls):\n",
    "    sensitivity_distinct = []\n",
    "    for i, score in enumerate(distinct):\n",
    "        positive = distinct[i:]\n",
    "        true_pos = len([score for score in positive if score[1] == 1])\n",
    "        sensitivity_distinct.append(true_pos / positive_lbls)\n",
    "    return sensitivity_distinct\n",
    "\n",
    "def specificity (distinct, negative_lbls):\n",
    "    specificity_distinct = []\n",
    "    for i, score in enumerate(distinct):\n",
    "        negative = distinct[:i]\n",
    "        true_neg = len([score for score in negative if score[1] == 0])\n",
    "        specificity_distinct.append(1 - true_neg / negative_lbls)\n",
    "    return specificity_distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auc output (score and plots) for the desired files\n",
    "def auc_output (test_file, train_file, alphabet_file, labels, n_values, r_values, title, title_num):\n",
    "    fig = plt.figure()\n",
    "\n",
    "    for n in n_values: \n",
    "        test_unique = unique_substrings(test_file, n)\n",
    "        for r in r_values:\n",
    "            results_anomaly = terminal_output_chunks(train_file, alphabet_file, test_unique, n, r)\n",
    "            anomaly_labels = tuple(zip(results_anomaly, labels))\n",
    "            sorted_distinct = sorted(anomaly_labels, key=lambda tup: tup[0])\n",
    "            \n",
    "            positive_lbls = len([x for x in labels if x == 1])\n",
    "            negative_lbls = len([x for x in labels if x == 0])\n",
    "            \n",
    "            sensitivity_auc = sensitivity(sorted_distinct, positive_lbls) \n",
    "            specificity_auc = specificity(sorted_distinct, negative_lbls)\n",
    "           \n",
    "            auc_roc_score = metrics.auc(specificity_auc, sensitivity_auc)\n",
    "            #auc_roc_score = metrics.roc_auc_score(labels, results_anomaly)\n",
    "            \n",
    "            plt.plot(specificity_auc, sensitivity_auc, label=f\"n={n}, r={r}; AUC: {np.round(auc_roc_score,3)}\")\n",
    "            \n",
    "    plt.plot([0, 1], [0, 1], lw=1, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('sensitivity')\n",
    "    plt.ylabel('1-specificity') \n",
    "    plt.legend()\n",
    "    plt.title(f\"ROC-curve, {title}.{title_num}\")\n",
    "\n",
    "    fig.savefig('{}/task2_ROC_{}_{}.png'.format(os.path.join(os.getcwd(), results_folder), title, title_num))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_values = [7] #chunk_size\n",
    "r_values = [1,3,5,7]\n",
    "\n",
    "for i in range(len(subfolders)):\n",
    "    for j in range(len(test_files_indexes)):\n",
    "        train_file = f\"{results_folder}/{subfolders[i]}.train\"\n",
    "        test_file = f\"{syscalls_folder}/{subfolders[i]}/{subfolders[i]}.{test_files_indexes[j]}.test\"\n",
    "        labels = load_labels(f\"{syscalls_folder}/{subfolders[i]}/{subfolders[i]}.{test_files_indexes[j]}.labels\")\n",
    "        alpha_file = f\"{syscalls_folder}/{subfolders[i]}/{subfolders[i]}.alpha\"\n",
    "        auc_output(test_file, train_file, alpha_file, labels, n_values, r_values, subfolders[i], test_files_indexes[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
